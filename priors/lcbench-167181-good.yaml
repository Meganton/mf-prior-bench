batch_size: 146
learning_rate: 0.01843747534667868
max_dropout: 0.5841386829859425
max_units: 164
momentum: 0.306567551934912
num_layers: 2
weight_decay: 0.08951880332013688
