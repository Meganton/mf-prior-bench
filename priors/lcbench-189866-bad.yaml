batch_size: 113
learning_rate: 0.08487096384931196
max_dropout: 0.0420872518130917
max_units: 160
momentum: 0.8851509185200785
num_layers: 5
weight_decay: 0.061841439137540186
