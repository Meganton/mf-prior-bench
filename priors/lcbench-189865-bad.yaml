batch_size: 98
learning_rate: 0.00017980977382219047
max_dropout: 0.622003234825716
max_units: 119
momentum: 0.3410483384247567
num_layers: 5
weight_decay: 0.09306910713554666
