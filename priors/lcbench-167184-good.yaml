batch_size: 38
learning_rate: 0.008153690297176724
max_dropout: 0.7073401870617128
max_units: 68
momentum: 0.45385350434472815
num_layers: 2
weight_decay: 0.00043269613592460083
