batch_size: 64
learning_rate: 0.004932327778648699
max_dropout: 0.2565737362113599
max_units: 699
momentum: 0.7073869393557137
num_layers: 2
weight_decay: 0.05613197551208648
