batch_size: 67
learning_rate: 0.0043299035224305645
max_dropout: 0.44619803471281727
max_units: 108
momentum: 0.32803719010581595
num_layers: 2
weight_decay: 0.03477970271760063
