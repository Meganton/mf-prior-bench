batch_size: 68
learning_rate: 0.0005818906911371712
max_dropout: 0.5701626404374125
max_units: 260
momentum: 0.4716522065790295
num_layers: 4
weight_decay: 0.03563595429380895
